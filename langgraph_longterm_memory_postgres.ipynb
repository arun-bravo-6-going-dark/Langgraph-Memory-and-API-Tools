{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph long term memory\n",
    "\n",
    "This notebook explains the concept of using long term memory to retain memory across different chats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Install necessary python packages through pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal, Optional\n",
    "\n",
    "import tiktoken\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.messages import get_buffer_string\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "import uuid\n",
    "from langchain_community.tools import DuckDuckGoSearchRun, DuckDuckGoSearchResults, WikipediaQueryRun\n",
    "\n",
    "from psycopg_pool import AsyncConnectionPool\n",
    "from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Embedding Model\n",
    "\n",
    "Used to convert Long term memory into embeddings and store in a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vector store for storing Longterm Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_vector_store = PGVector(\n",
    "    embeddings=hf,\n",
    "    collection_name=\"long_term_memory\",\n",
    "    connection=\"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_id(config: RunnableConfig) -> str:\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    if user_id is None:\n",
    "        raise ValueError(\"User ID needs to be provided to save a memory.\")\n",
    "\n",
    "    return user_id\n",
    "\n",
    "@tool\n",
    "def save_recall_memory(memory: str, config: RunnableConfig) -> str:\n",
    "    \"\"\"Save memory to vectorstore for later semantic retrieval.\"\"\"\n",
    "    user_id = get_user_id(config)\n",
    "    print(\"Memories to save:\", memory)\n",
    "    document = Document(\n",
    "        page_content=memory, id=str(uuid.uuid4()), metadata={\"user_id\": user_id}\n",
    "    )\n",
    "    recall_vector_store.add_documents([document])\n",
    "    print(\"Memory Updated\")\n",
    "    return memory\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_recall_memories(query: str, config: RunnableConfig) -> List[str]:\n",
    "    \"\"\"Search for relevant memories.\"\"\"\n",
    "    user_id = get_user_id(config)\n",
    "    \n",
    "    # Filter as a dictionary\n",
    "    filter_dict = {\"user_id\": user_id}\n",
    "\n",
    "\n",
    "    documents = recall_vector_store.similarity_search(\n",
    "        query, k=3, filter=filter_dict\n",
    "    )\n",
    "    return [document.page_content for document in documents]\n",
    "\n",
    "@tool\n",
    "def wikipedia_tool(search_string: str):\n",
    "    \"\"\"\n",
    "    Retrieves information from wikipedia based on the provided query.\n",
    "    \"\"\"\n",
    "    wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "    wiki_results = wikipedia.run(search_string)\n",
    "    return wiki_results\n",
    "\n",
    "@tool\n",
    "def ddg(search_string: str):\n",
    "    \"\"\"\n",
    "    Retrieves information from the internet based on the provided query.\n",
    "    \"\"\"\n",
    "    search = DuckDuckGoSearchResults()\n",
    "    ddg_results = search.invoke(search_string)\n",
    "    return ddg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [save_recall_memory, search_recall_memories, ddg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    # add memories that will be retrieved based on the conversation context\n",
    "    recall_memories: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt for Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template for the agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant with advanced long-term memory designed to support students working on Capstone projects.\"\n",
    "            \" Powered by a stateless LLM, you rely on external memory tools to store and retrieve  information across conversations.\"\n",
    "            \" Your goal is to assist students effectively by retaining relevant project details, progress updates, and challenges they share with you.\\n\\n\"\n",
    "            \"Memory Usage Guidelines:\\n\"\n",
    "            \"1. Actively use memory tools (save_recall_memory) to store important project-related details:\"\n",
    "            \"    - Project topics and titles.\\n\"\n",
    "            \"    - Objectives, hypotheses, or research questions.\\n\"\n",
    "            \"    - Key milestones, deadlines, and timelines.\\n\"\n",
    "            \"    - Technical challenges, tools, or methods discussed.\\n\"\n",
    "            \"    - Feedback received from advisors or peers.\\n\"\n",
    "            \"    - Emotional context, such as stress levels, excitement, or confidence about the project.\\n\"\n",
    "            \"    - Suggestions, resources, or advice provided by you.\\n\"\n",
    "            \"    - Personal preferences, such as preferred tools or styles of working.\\n\\n\"\n",
    "            \"2. Store information only when it is critical for long-term context or directly relevant to\"\n",
    "            \" the project, not for general or fleeting details.\\n\"\n",
    "            \"3. Reflect on past conversations to adapt to the student’s changing needs, offering\"\n",
    "            \" tailored advice and encouragement.\\n\"\n",
    "            \"4. Regularly update stored memories to ensure the information reflects the latest progress\"\n",
    "            \" or any changes in project scope or goals.\\n\"\n",
    "            \"5. Cross-reference new information with existing memories for\"\n",
    "            \" consistency.\\n\"\n",
    "            \"6. Prioritize storing information that can be referenced to:\\n\"\n",
    "            \"    - Track progress effectively.\\n\"\n",
    "            \"    - Remind the student of past decisions or achievements.\\n\"\n",
    "            \"    - Provide consistency in discussions.\\n\"\n",
    "            \"    - Anticipate challenges or upcoming tasks.\\n\\n\"\n",
    "            \"7. Prioritize storing emotional context and personal values\"\n",
    "            \" alongside facts.\\n\"\n",
    "            \"8. Use memory to anticipate needs and tailor responses to the\"\n",
    "            \" student's style.\\n\"\n",
    "            \"9. Recognize and acknowledge changes in the student's situation or\"\n",
    "            \" perspectives over time.\\n\"\n",
    "            \"10. Leverage memories to provide personalized examples and\"\n",
    "            \" analogies.\\n\"\n",
    "            \"11. Recall past challenges or successes to inform current\"\n",
    "            \" problem-solving.\\n\\n\"\n",
    "            \"## Recall Memories\\n\"\n",
    "            \"Recall memories are contextually retrieved based on the current\"\n",
    "            \" conversation:\\n{recall_memories}\\n\\n\"\n",
    "            \"## Instructions\\n\"\n",
    "            \"Engage with the student naturally, as a trusted mentor or peer.\"\n",
    "            \" There's no need to explicitly mention your memory capabilities.\"\n",
    "            \" Instead, seamlessly incorporate your understanding of the student\"\n",
    "            \" into your responses. Be attentive to subtle cues and underlying\"\n",
    "            \" emotions. Adapt your communication style to match the user's\"\n",
    "            \" preferences and current emotional state. Be proactive in identifying\"\n",
    "            \" opportunities to store critical project-related information, and use\"\n",
    "            \" it to provide meaningful, personalized support.\\n\\n\"\n",
    "            \"When important information arises, call the `save_recall_memory`\"\n",
    "            \" tool to retain it. Confirm successful storage of memories before\"\n",
    "            \" proceeding. Avoid storing information unnecessarily; focus on details\"\n",
    "            \" that will enhance the student’s experience and project outcomes.\"\n",
    "            \" Respond AFTER tool confirmation, ensuring your response reflects\"\n",
    "            \" the current state of memory.\\n\\n\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_with_tools = ChatOpenAI(model=\"gpt-4o-mini\", \n",
    "                              api_key=os.environ[\"OPENAI_API_KEY\"], \n",
    "                              temperature=0, top_p=0.5).bind_tools(tools)\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state: State) -> State:\n",
    "    \"\"\"Process the current state and generate a response using the LLM.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "\n",
    "    Returns:\n",
    "        schemas.State: The updated state with the agent's response.\n",
    "    \"\"\"\n",
    "    bound = prompt | model_with_tools\n",
    "    recall_str = (\n",
    "        \"<recall_memory>\\n\" + \"\\n\".join(state[\"recall_memories\"]) + \"\\n</recall_memory>\"\n",
    "    )\n",
    "    prediction = bound.invoke(\n",
    "        {\n",
    "            \"messages\": state[\"messages\"],\n",
    "            \"recall_memories\": recall_str,\n",
    "        }\n",
    "    )\n",
    "    return {\n",
    "        \"messages\": [prediction],\n",
    "    }\n",
    "\n",
    "\n",
    "def load_memories(state: State, config: RunnableConfig) -> State:\n",
    "    \"\"\"Load memories for the current conversation.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "        config (RunnableConfig): The runtime configuration for the agent.\n",
    "\n",
    "    Returns:\n",
    "        State: The updated state with loaded memories.\n",
    "    \"\"\"\n",
    "    convo_str = get_buffer_string(state[\"messages\"])\n",
    "    convo_str = tokenizer.decode(tokenizer.encode(convo_str)[:2048])\n",
    "    recall_memories = search_recall_memories.invoke(convo_str, config)\n",
    "    print(\"Recalled Memories:\", recall_memories)\n",
    "    return {\n",
    "        \"recall_memories\": recall_memories,\n",
    "    }\n",
    "\n",
    "\n",
    "def route_tools(state: State):\n",
    "    \"\"\"Determine whether to use tools or end the conversation based on the last message.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "\n",
    "    Returns:\n",
    "        Literal[\"tools\", \"__end__\"]: The next step in the graph.\n",
    "    \"\"\"\n",
    "    msg = state[\"messages\"][-1]\n",
    "    if msg.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostgresDB Connection for Short Term Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Presrequisites for local Postgres: brew update -> brew install postgres -> brew services start postgresql -> psql postgres -> CREATE DATABASE my_database; -> CREATE USER my_user WITH PASSWORD 'my_password'; -> GRANT ALL PRIVILEGES ON DATABASE my_database TO my_user; -> \\q\n",
    "DB_URI = \"postgresql://my_user:my_password@localhost:5432/my_database?sslmode=disable\"\n",
    "connection_kwargs = {\n",
    "    \"autocommit\": True,\n",
    "    \"prepare_threshold\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph and add nodes\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(load_memories)\n",
    "builder.add_node(agent)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Add edges to the graph\n",
    "builder.add_edge(START, \"load_memories\")\n",
    "builder.add_edge(\"load_memories\", \"agent\")\n",
    "builder.add_conditional_edges(\"agent\", route_tools, [\"tools\", END])\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# # Compile the graph\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "my name is John\n",
      "Recalled Memories: []\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "my name is John\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it, John! How can I help you with your Capstone project today?\n"
     ]
    }
   ],
   "source": [
    "async with AsyncConnectionPool(\n",
    "    conninfo=DB_URI,\n",
    "    max_size=20,\n",
    "    kwargs=connection_kwargs,\n",
    ") as pool:\n",
    "    checkpointer = AsyncPostgresSaver(pool)\n",
    "\n",
    "    # NOTE: you need to call .setup() the first time you're using your checkpointer\n",
    "    await checkpointer.setup()\n",
    "\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "    config = {\"configurable\": {\"user_id\": \"246463233523\", \"thread_id\": \"postgrestest_7\"}}\n",
    "    input_message = {\"type\": \"user\", \"content\": \"my name is John\"}\n",
    "    async for chunk in graph.astream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "    checkpoint = await checkpointer.aget(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "i love developing mobile applications.\n",
      "Recalled Memories: []\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "i love developing mobile applications.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (call_EB2hf0LfBiPcBxEA7sdovEsq)\n",
      " Call ID: call_EB2hf0LfBiPcBxEA7sdovEsq\n",
      "  Args:\n",
      "    memory: User's name is John, and he loves developing mobile applications.\n",
      "Memories to save: User's name is John, and he loves developing mobile applications.\n",
      "Memory Updated\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "User's name is John, and he loves developing mobile applications.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great to hear, John! Mobile application development is an exciting field. Are you working on a specific project or idea for your Capstone related to mobile apps?\n"
     ]
    }
   ],
   "source": [
    "async with AsyncConnectionPool(\n",
    "    conninfo=DB_URI,\n",
    "    max_size=20,\n",
    "    kwargs=connection_kwargs,\n",
    ") as pool:\n",
    "    checkpointer = AsyncPostgresSaver(pool)\n",
    "\n",
    "    # NOTE: you need to call .setup() the first time you're using your checkpointer\n",
    "    await checkpointer.setup()\n",
    "\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "    config = {\"configurable\": {\"user_id\": \"246463233523\", \"thread_id\": \"postgrestest_7\"}}\n",
    "    input_message = {\"type\": \"user\", \"content\": \"i love developing mobile applications.\"}\n",
    "    async for chunk in graph.astream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "    checkpoint = await checkpointer.aget(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What applications do I love developing?\n",
      "Recalled Memories: [\"User's name is John, and he loves developing mobile applications.\"]\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What applications do I love developing?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You love developing mobile applications.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "async with AsyncConnectionPool(\n",
    "    # Example configuration\n",
    "    conninfo=DB_URI,\n",
    "    max_size=20,\n",
    "    kwargs=connection_kwargs,\n",
    ") as pool:\n",
    "    checkpointer = AsyncPostgresSaver(pool)\n",
    "\n",
    "    # NOTE: you need to call .setup() the first time you're using your checkpointer\n",
    "    await checkpointer.setup()\n",
    "\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "    \n",
    "    #Changing the thread_id to check if long term memory is retained.\n",
    "    config = {\"configurable\": {\"user_id\": \"246463233523\", \"thread_id\": \"postgrestest_8\"}}\n",
    "    input_message = {\"type\": \"user\", \"content\": \"What applications do I love developing?\"}\n",
    "    async for chunk in graph.astream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "    # res = graph.invoke({\"messages\": [(\"human\", \"hi! I'm bob\")]}, config)\n",
    "    checkpoint = await checkpointer.aget(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalled Memories: [\"User's name is John, and he loves developing mobile applications.\"]\n",
      "To develop an iOS app, you'll typically need the following tools:\n",
      "\n",
      "1. **Xcode**: The official integrated development environment (IDE) for macOS, used for developing iOS applications. It includes a code editor, interface builder, and debugging tools.\n",
      "\n",
      "2. **Swift**: The primary programming language for iOS development. Familiarity with Swift is essential for writing iOS apps.\n",
      "\n",
      "3. **Cocoa Touch**: A framework that provides the necessary infrastructure for building iOS apps, including UI components and event handling.\n",
      "\n",
      "4. **Simulator**: Built into Xcode, it allows you to test your app on various iOS devices without needing physical hardware.\n",
      "\n",
      "5. **TestFlight**: A platform for beta testing your app with real users before the official release.\n",
      "\n",
      "6. **Git**: A version control system to manage your code and collaborate with others.\n",
      "\n",
      "7. **CocoaPods or Swift Package Manager**: Dependency managers that help you integrate third-party libraries into your project.\n",
      "\n",
      "8. **Design Tools**: Tools like Sketch, Figma, or Adobe XD for designing your app's user interface and user experience.\n",
      "\n",
      "9. **Apple Developer Account**: Required for app distribution on the App Store and access to certain development resources.\n",
      "\n",
      "10. **Documentation and Resources**: Access to Apple's developer documentation and online resources like Stack Overflow for troubleshooting and learning.\n",
      "\n",
      "These tools will help you effectively develop, test, and deploy your iOS applications."
     ]
    }
   ],
   "source": [
    "from psycopg_pool import ConnectionPool\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "question = \"List the tools that I need to develop an iOS app.\"\n",
    "\n",
    "with ConnectionPool(\n",
    "    # Example configuration\n",
    "    conninfo=DB_URI,\n",
    "    max_size=20,\n",
    "    kwargs=connection_kwargs,\n",
    ") as pool:\n",
    "    checkpointer = PostgresSaver(pool)\n",
    "\n",
    "    # NOTE: you need to call .setup() the first time you're using your checkpointer\n",
    "    checkpointer.setup()\n",
    "\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "    config = {\"configurable\": {\"user_id\": \"246463233523\", \"thread_id\": \"postgrestest_8\"}}\n",
    "    input_message = {\"messages\": [HumanMessage(content=question)]}\n",
    "    \n",
    "    for msg, metadata in graph.stream(input_message, config, stream_mode=\"messages\"):\n",
    "        if (\n",
    "            isinstance(msg, AIMessage)  # Check if msg is of type AIMessage\n",
    "            and metadata[\"langgraph_node\"] == \"agent\"\n",
    "        ):\n",
    "            print(msg.content, end=\"\", flush=True)\n",
    "    \n",
    "    checkpoint = checkpointer.get(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm doing a project based learning on the topic smart agriculture using IoT. Let's create project stages.\n",
    "Let's move on to the with the first stage.\n",
    "Let's move on to the next stage.\n",
    "Let's close this stage and I'll start a new conversation for the next stage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
